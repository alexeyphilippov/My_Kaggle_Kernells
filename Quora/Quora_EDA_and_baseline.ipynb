{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "import gensim\n",
    "\n",
    "from gensim import models, corpora\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train datasets shape: (1306122, 3)\n",
      "Test datasets shape: (56370, 2)\n"
     ]
    }
   ],
   "source": [
    "data_train_gen = pd.read_csv(\"/Users/aleksejfilippov/Desktop/techotrack/quora_2/csvs/train.csv\")\n",
    "data_test = pd.read_csv(\"/Users/aleksejfilippov/Desktop/techotrack/quora_2/csvs/test.csv\")\n",
    "print(\"Train datasets shape:\", data_train_gen.shape)\n",
    "print(\"Test datasets shape:\", data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Lemmatization, class ratio, getting rid of stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 653826\n",
    "bad_df = data_train_gen[data_train_gen.target == 1]\n",
    "good_df = data_train_gen[data_train_gen.target == 0][:num]\n",
    "data_train = pd.concat([bad_df, good_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "data_train = shuffle(data_train)\n",
    "data_train = data_train[:136520]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiestion_words = ['what','when','why','which','who','how', 'whose', 'whome', 'people', 'i', \n",
    "                  'n\\'t','\\'s','like','get','would','would']\n",
    "stop_signs = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']\n",
    "stop_words = stopwords.words('english')\n",
    "for w in quiestion_words:\n",
    "    stop_words.append(w)\n",
    "for w in stop_signs:\n",
    "    stop_words.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_questions_train = []\n",
    " \n",
    "for sentence in data_train['question_text']:\n",
    "    new_sentence = [wordnet_lemmatizer.lemmatize(w).lower() for w in word_tokenize(sentence)]\n",
    "    new_sentence = [w for w in new_sentence if w not in stop_words]\n",
    "    new_sentence = [w for w in new_sentence if len(w)>3]\n",
    "         \n",
    "    clean = ' '.join(new_sentence)    \n",
    "   \n",
    "    cleaned_questions_train.append(clean)\n",
    "\n",
    "cleaned_questions_test = []\n",
    "for sentence in data_test['question_text']:\n",
    "    new_sentence = [wordnet_lemmatizer.lemmatize(w).lower() for w in word_tokenize(sentence)]\n",
    "    new_sentence = [w for w in new_sentence if w not in stop_words]\n",
    "    new_sentence = [w for w in new_sentence if len(w)>3]\n",
    "         \n",
    "    clean = ' '.join(new_sentence)    \n",
    "   \n",
    "    cleaned_questions_test.append(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.insert(loc=0, column=\"debugged_questions\", value=cleaned_questions_train)\n",
    "data_test.insert(loc=0, column=\"debugged_questions\", value=cleaned_questions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.fillna('', inplace = True)\n",
    "data_test.fillna('', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aleksejfilippov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/aleksejfilippov/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train = data_train.ix[:, (1,0, 3)]\n",
    "test = data_test.ix[:, (1,0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2  word2vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tokens_list'] = train.debugged_questions.apply(lambda x: x.split())\n",
    "test['tokens_list'] = test.debugged_questions.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_path = \"GoogleNews-vectors-negative300.bin\"\n",
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_word2vec(tokens_list, vector, generate_missing=False, k=300):\n",
    "    if len(tokens_list)<1:\n",
    "        return np.zeros(k)\n",
    "    if generate_missing:\n",
    "        vectorized = [vector[word] if word in vector else np.random.rand(k) for word in tokens_list]\n",
    "    else:\n",
    "        vectorized = [vector[word] if word in vector else np.zeros(k) for word in tokens_list]\n",
    "    length = len(vectorized)\n",
    "    summed = np.sum(vectorized, axis=0)\n",
    "    averaged = np.divide(summed, length)\n",
    "    return averaged\n",
    "\n",
    "def get_word2vec_embeddings(vectors, clean_questions, generate_missing=False):\n",
    "    embeddings = clean_questions['tokens_list'].apply(lambda x: get_average_word2vec(x, vectors, \n",
    "                                                                                generate_missing=generate_missing))\n",
    "    return embeddings.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = get_word2vec_embeddings(word2vec, test)\n",
    "train_embeddings = get_word2vec_embeddings(word2vec, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = pd.DataFrame(test_embeddings)\n",
    "train_embeddings = pd.DataFrame(train_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ну или импортирую заранее обученную\n",
    "ldamodel = models.ldamodel.LdaModel.load(\"ldamodel3_lkcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = pd.concat([train[train.columns[[0,1,3]]], test], axis = 0)\n",
    "tokens = gen.tokens_list.tolist()\n",
    "dictionary = corpora.Dictionary(tokens)\n",
    "corpus = []\n",
    "for token in tokens: corpus.append(dictionary.doc2bow(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "tetok = test.tokens_list.tolist()\n",
    "trtok = train.tokens_list.tolist()\n",
    "# wtok = weird_tok.tolist()\n",
    "tecor = []\n",
    "trcor = []\n",
    "# wecor = []\n",
    "for token in tetok: tecor.append(dictionary.doc2bow(token))\n",
    "for token in trtok: trcor.append(dictionary.doc2bow(token))\n",
    "# for token in wtok: wecor.append(dictionary2.doc2bow(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(76543)\n",
    "%time ldamodel_orig = models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=200, passes=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create matrix Theta describing the destribution of topics above documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_topics = ldamodel.get_document_topics(tecor)\n",
    "train_topics = ldamodel.get_document_topics(trcor)\n",
    "# weird_topics = ldamodel.get_document_topics(wecor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums1 = []\n",
    "for list in [ldamodel.get_document_topics(corp) for corp in trcor]:\n",
    "    num1 = []\n",
    "    for tup in list:\n",
    "        num1.append(tup)\n",
    "    nums1.append(num1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "nums2 = []\n",
    "nn = []\n",
    "for list in [ldamodel.get_document_topics(corp) for corp in tecor]:\n",
    "    num2 = []\n",
    "    for tup in list:\n",
    "        num2.append(tup)\n",
    "    nums2.append(num2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ps_tr = np.ndarray([len(trcor), 200])\n",
    "X_ps_te = np.ndarray([len(tecor), 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(nums1)):\n",
    "    if i == 136523: pass\n",
    "    for j in range(len(nums1[i])):\n",
    "        X_ps_tr[i, nums1[i][j][0]] = nums1[i][j][1]\n",
    "        \n",
    "        \n",
    "for i in range(len(nums2)):\n",
    "    for j in range(len(nums2[i])):\n",
    "        X_ps_te[i, nums2[i][j][0]] = nums2[i][j][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ps_te = pd.DataFrame(X_ps_te)\n",
    "X_ps_tr = pd.DataFrame(X_ps_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.index = pd.RangeIndex(0, train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainig = pd.concat([train.qid, train.target, train_embeddings, X_ps_tr], axis = 1)\n",
    "testing = pd.concat([test.qid, test_embeddings, X_ps_te], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00014894849d00ba98a9</td>\n",
       "      <td>0.012553</td>\n",
       "      <td>0.043992</td>\n",
       "      <td>-0.030441</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>-0.093994</td>\n",
       "      <td>0.026571</td>\n",
       "      <td>0.015569</td>\n",
       "      <td>-0.117981</td>\n",
       "      <td>0.156372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000156468431f09b3cae</td>\n",
       "      <td>0.011292</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>-0.113220</td>\n",
       "      <td>0.278564</td>\n",
       "      <td>-0.031006</td>\n",
       "      <td>0.019897</td>\n",
       "      <td>0.074738</td>\n",
       "      <td>-0.157593</td>\n",
       "      <td>-0.014236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000227734433360e1aae</td>\n",
       "      <td>-0.031982</td>\n",
       "      <td>-0.026709</td>\n",
       "      <td>0.134375</td>\n",
       "      <td>0.013586</td>\n",
       "      <td>-0.016016</td>\n",
       "      <td>-0.015918</td>\n",
       "      <td>-0.046609</td>\n",
       "      <td>-0.020842</td>\n",
       "      <td>0.155200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0005e06fbe3045bd2a92</td>\n",
       "      <td>0.006824</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.029579</td>\n",
       "      <td>0.098839</td>\n",
       "      <td>-0.109790</td>\n",
       "      <td>0.030280</td>\n",
       "      <td>0.126740</td>\n",
       "      <td>-0.022961</td>\n",
       "      <td>0.186877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00068a0f7f41f50fc399</td>\n",
       "      <td>-0.140299</td>\n",
       "      <td>0.013590</td>\n",
       "      <td>0.075195</td>\n",
       "      <td>0.100423</td>\n",
       "      <td>0.008138</td>\n",
       "      <td>0.076660</td>\n",
       "      <td>-0.029948</td>\n",
       "      <td>-0.061646</td>\n",
       "      <td>-0.031657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid         0         1         2         3         4  \\\n",
       "0  00014894849d00ba98a9  0.012553  0.043992 -0.030441  0.000315 -0.093994   \n",
       "1  000156468431f09b3cae  0.011292  0.013550 -0.113220  0.278564 -0.031006   \n",
       "2  000227734433360e1aae -0.031982 -0.026709  0.134375  0.013586 -0.016016   \n",
       "3  0005e06fbe3045bd2a92  0.006824  0.006291  0.029579  0.098839 -0.109790   \n",
       "4  00068a0f7f41f50fc399 -0.140299  0.013590  0.075195  0.100423  0.008138   \n",
       "\n",
       "          5         6         7         8 ...   190  191  192  193  194  195  \\\n",
       "0  0.026571  0.015569 -0.117981  0.156372 ...   0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  0.019897  0.074738 -0.157593 -0.014236 ...   0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2 -0.015918 -0.046609 -0.020842  0.155200 ...   0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3  0.030280  0.126740 -0.022961  0.186877 ...   0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  0.076660 -0.029948 -0.061646 -0.031657 ...   0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   196  197  198  199  \n",
       "0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 501 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(n_components=100)\n",
    "lsa.fit(trainig[trainig.columns[2:]])\n",
    "lsa_scores_train = lsa.transform(trainig[trainig.columns[2:]])\n",
    "lsa_scores_test = lsa.transform(testing[testing.columns[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa_scores_train = pd.DataFrame(lsa_scores_train)\n",
    "lsa_scores_test = pd.DataFrame(lsa_scores_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = trainig.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=12,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=20, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth = 12, min_samples_leaf = 20)\n",
    "clf.fit(lsa_scores_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({'qid':testing.qid.values})\n",
    "sub_df['prediction'] = clf.predict(lsa_scores_test)\n",
    "sub_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_traint, X_testt, y_train, y_test = train_test_split(lsa_scores_train, y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from collections import OrderedDict\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "import itertools\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow0_col1 {\n",
       "            background-color:  #e4ff7a;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow0_col2 {\n",
       "            background-color:  #e4ff7a;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow0_col3 {\n",
       "            background-color:  #e4ff7a;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow0_col4 {\n",
       "            background-color:  #e4ff7a;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow1_col1 {\n",
       "            background-color:  #ffb400;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow1_col2 {\n",
       "            background-color:  #ffb700;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow1_col3 {\n",
       "            background-color:  #ffc303;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow1_col4 {\n",
       "            background-color:  #ffcc09;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow2_col1 {\n",
       "            background-color:  #fc7f00;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow2_col2 {\n",
       "            background-color:  #fc8000;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow2_col3 {\n",
       "            background-color:  #fe9a00;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow2_col4 {\n",
       "            background-color:  #ff9e00;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow3_col1 {\n",
       "            background-color:  #fc8200;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow3_col2 {\n",
       "            background-color:  #fc8200;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow3_col3 {\n",
       "            background-color:  #fd8b00;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow3_col4 {\n",
       "            background-color:  #fe9300;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow4_col1 {\n",
       "            background-color:  #fc8100;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow4_col2 {\n",
       "            background-color:  #fc8300;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow4_col3 {\n",
       "            background-color:  #fc8300;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow4_col4 {\n",
       "            background-color:  #fd8800;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow5_col1 {\n",
       "            background-color:  #fd8500;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow5_col2 {\n",
       "            background-color:  #fc7f00;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow5_col3 {\n",
       "            background-color:  #fc8100;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow5_col4 {\n",
       "            background-color:  #fc8300;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow6_col1 {\n",
       "            background-color:  #fd8c00;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow6_col2 {\n",
       "            background-color:  #fc8400;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow6_col3 {\n",
       "            background-color:  #fc7f00;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow6_col4 {\n",
       "            background-color:  #fc7f00;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow7_col1 {\n",
       "            background-color:  #fe9300;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow7_col2 {\n",
       "            background-color:  #fd8e00;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow7_col3 {\n",
       "            background-color:  #fc8000;\n",
       "        }    #T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow7_col4 {\n",
       "            background-color:  #fc7f00;\n",
       "        }</style>  \n",
       "<table id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580c\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >params</th> \n",
       "        <th class=\"col_heading level0 col1\" >roc_auc_train</th> \n",
       "        <th class=\"col_heading level0 col2\" >roc_auc_valid</th> \n",
       "        <th class=\"col_heading level0 col3\" >f1_train</th> \n",
       "        <th class=\"col_heading level0 col4\" >f1_valid</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580clevel0_row0\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow0_col0\" class=\"data row0 col0\" >{'max_depth': 12, 'min_samples_leaf': 20}</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow0_col1\" class=\"data row0 col1\" >0.745557</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow0_col2\" class=\"data row0 col2\" >0.745601</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow0_col3\" class=\"data row0 col3\" >0.590453</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow0_col4\" class=\"data row0 col4\" >0.589319</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580clevel0_row1\" class=\"row_heading level0 row1\" >1</th> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow1_col0\" class=\"data row1 col0\" >{'max_depth': 13, 'min_samples_leaf': 20}</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow1_col1\" class=\"data row1 col1\" >0.758936</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow1_col2\" class=\"data row1 col2\" >0.757009</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow1_col3\" class=\"data row1 col3\" >0.61472</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow1_col4\" class=\"data row1 col4\" >0.610439</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580clevel0_row2\" class=\"row_heading level0 row2\" >2</th> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow2_col0\" class=\"data row2 col0\" >{'max_depth': 14, 'min_samples_leaf': 20}</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow2_col1\" class=\"data row2 col1\" >0.768809</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow2_col2\" class=\"data row2 col2\" >0.766169</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow2_col3\" class=\"data row2 col3\" >0.631735</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow2_col4\" class=\"data row2 col4\" >0.628097</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580clevel0_row3\" class=\"row_heading level0 row3\" >3</th> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow3_col0\" class=\"data row3 col0\" >{'max_depth': 15, 'min_samples_leaf': 20}</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow3_col1\" class=\"data row3 col1\" >0.768269</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow3_col2\" class=\"data row3 col2\" >0.765813</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow3_col3\" class=\"data row3 col3\" >0.637441</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow3_col4\" class=\"data row3 col4\" >0.63232</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580clevel0_row4\" class=\"row_heading level0 row4\" >4</th> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow4_col0\" class=\"data row4 col0\" >{'max_depth': 16, 'min_samples_leaf': 20}</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow4_col1\" class=\"data row4 col1\" >0.768424</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow4_col2\" class=\"data row4 col2\" >0.765687</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow4_col3\" class=\"data row4 col3\" >0.640603</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow4_col4\" class=\"data row4 col4\" >0.636602</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580clevel0_row5\" class=\"row_heading level0 row5\" >5</th> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow5_col0\" class=\"data row5 col0\" >{'max_depth': 17, 'min_samples_leaf': 20}</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow5_col1\" class=\"data row5 col1\" >0.767768</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow5_col2\" class=\"data row5 col2\" >0.766342</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow5_col3\" class=\"data row5 col3\" >0.641688</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow5_col4\" class=\"data row5 col4\" >0.638559</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580clevel0_row6\" class=\"row_heading level0 row6\" >6</th> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow6_col0\" class=\"data row6 col0\" >{'max_depth': 18, 'min_samples_leaf': 20}</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow6_col1\" class=\"data row6 col1\" >0.766524</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow6_col2\" class=\"data row6 col2\" >0.765586</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow6_col3\" class=\"data row6 col3\" >0.64241</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow6_col4\" class=\"data row6 col4\" >0.640192</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580clevel0_row7\" class=\"row_heading level0 row7\" >7</th> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow7_col0\" class=\"data row7 col0\" >{'max_depth': 19, 'min_samples_leaf': 20}</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow7_col1\" class=\"data row7 col1\" >0.765181</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow7_col2\" class=\"data row7 col2\" >0.76397</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow7_col3\" class=\"data row7 col3\" >0.642119</td> \n",
       "        <td id=\"T_37af1d76_16ac_11e9_8e7e_d0e1408c580crow7_col4\" class=\"data row7 col4\" >0.640071</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b3883cf28>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = OrderedDict((\n",
    "        ('max_depth',np.arange(12,20,1)),\n",
    "        ('min_samples_leaf', [20])))\n",
    "\n",
    "result = {'params':[],'roc_auc_train':[],'roc_auc_valid':[], 'f1_train':[], 'f1_valid':[]}\n",
    "\n",
    "for param_values in itertools.product(*grid.values()):\n",
    "    param = dict(zip(grid.keys(),param_values))\n",
    "    clf = DecisionTreeClassifier(**param)\n",
    "\n",
    "    clf.fit(lsa_scores_train,y)\n",
    "\n",
    "    train_pred = clf.predict(X_traint)\n",
    "    valid_pred = clf.predict(X_testt)\n",
    "\n",
    "    roc_auc_train = roc_auc_score(y_train,train_pred)\n",
    "    roc_auc_valid = roc_auc_score(y_test,valid_pred)\n",
    "    f1_train = f1_score(y_train,train_pred)\n",
    "    f1_test = f1_score(y_test,valid_pred)\n",
    "    result['params'].append(param)\n",
    "    result['roc_auc_train'].append(roc_auc_train)\n",
    "    result['roc_auc_valid'].append(roc_auc_valid)\n",
    "    result['f1_train'].append(f1_train)\n",
    "    result['f1_valid'].append(f1_test)\n",
    "\n",
    "(pd.DataFrame(result)   \n",
    "   .style\n",
    "   .background_gradient('Wistia')\n",
    ")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
